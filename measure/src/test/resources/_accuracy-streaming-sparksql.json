{
  "name": "accu_streaming",

  "process.type": "streaming",

  "data.sources": [
    {
      "name": "source",
      "baseline": true,
      "connectors": [
        {
          "type": "kafka",
          "version": "0.8",
          "config": {
            "kafka.config": {
              "bootstrap.servers": "10.149.247.156:9092",
              "group.id": "group1",
              "auto.offset.reset": "smallest",
              "auto.commit.enable": "false"
            },
            "topics": "sss",
            "key.type": "java.lang.String",
            "value.type": "java.lang.String"
          },
          "pre.proc": [
            {
              "dsl.type": "df-opr",
              "name": "${s1}",
              "rule": "from_json",
              "details": {
                "df.name": "${this}"
              }
            },
            {
              "dsl.type": "spark-sql",
              "name": "${this}",
              "rule": "select name, age from ${s1}"
            }
          ]
        }
      ],
      "cache": {
        "file.path": "hdfs://localhost/griffin/streaming/dump/source",
        "info.path": "source",
        "ready.time.interval": "10s",
        "ready.time.delay": "0",
        "time.range": ["-2m", "0"]
      }
    }, {
      "name": "target",
      "connectors": [
        {
          "type": "kafka",
          "version": "0.8",
          "config": {
            "kafka.config": {
              "bootstrap.servers": "10.149.247.156:9092",
              "group.id": "group1",
              "auto.offset.reset": "smallest",
              "auto.commit.enable": "false"
            },
            "topics": "ttt",
            "key.type": "java.lang.String",
            "value.type": "java.lang.String"
          },
          "pre.proc": [
            {
              "dsl.type": "df-opr",
              "name": "${t1}",
              "rule": "from_json",
              "details": {
                "df.name": "${this}"
              }
            },
            {
              "dsl.type": "spark-sql",
              "name": "${this}",
              "rule": "select name, age from ${t1}"
            }
          ]
        }
      ],
      "cache": {
        "file.path": "hdfs://localhost/griffin/streaming/dump/target",
        "info.path": "target",
        "ready.time.interval": "10s",
        "ready.time.delay": "0",
        "time.range": ["-2m", "0"]
      }
    }
  ],

  "evaluate.rule": {
    "rules": [
      {
        "dsl.type": "spark-sql",
        "name": "missRecords",
        "rule": "SELECT source.* FROM source LEFT JOIN target ON coalesce(source.name, '') = coalesce(target.name, '') AND coalesce(source.age, '') = coalesce(target.age, '') WHERE (NOT (source.name IS NULL AND source.age IS NULL)) AND (target.name IS NULL AND target.age IS NULL)"
      },
      {
        "dsl.type": "spark-sql",
        "name": "miss_count",
        "rule": "SELECT `__tmst`, count(*) as miss FROM `missRecords` GROUP BY `__tmst`"
      },
      {
        "dsl.type": "spark-sql",
        "name": "total_count",
        "rule": "SELECT `__tmst`, count(*) as total FROM source GROUP BY `__tmst`"
      },
      {
        "dsl.type": "spark-sql",
        "name": "accu",
        "rule": "SELECT `miss_count`.`__tmst`, `miss_count`.`miss` AS `miss`, `total_count`.`total` AS `total`, (`total` - `miss`) AS `matched` FROM `miss_count` FULL JOIN `total_count` ON `miss_count`.`__tmst` = `total_count`.`__tmst`"
      },
      {
        "dsl.type": "spark-sql",
        "name": "global_accu",
        "global": true,
        "global.init.rule": "SELECT *, (true) AS `__metric`, (true) AS `__record` FROM `accu`",
        "rule": "SELECT coalesce(`global_accu`.`__tmst`, `accu`.`__tmst`) AS `__tmst`, coalesce(`accu`.`miss`, `global_accu`.`miss`) AS `miss`, coalesce(`global_accu`.`total`, `accu`.`total`) AS `total`, (`total` - `miss`) AS `matched`, (`accu`.`miss` < `global_accu`.`miss`) AS `__metric`, (`__metric` AND `matched` > 0) AS `__record` FROM `global_accu` FULL JOIN `accu` ON `global_accu`.`__tmst` = `accu`.`__tmst`"
      },
      {
        "dsl.type": "spark-sql",
        "name": "metric_accu",
        "rule": "SELECT * FROM `global_accu` WHERE `__metric`",
        "metric": {
          "name": "accu"
        }
      },
      {
        "dsl.type": "spark-sql",
        "name": "record_accu",
        "rule": "SELECT * FROM `global_accu` WHERE `__record`",
        "record": {
          "name": "missRecords",
          "update.data.source": "source",
          "origin.DF": "missRecords"
        }
      }
    ]
  }
}